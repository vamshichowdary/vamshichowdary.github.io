---
title: "Predicting Generalization in Deep Learning via Local Measures of Distortion"
collection: Reports
permalink: /publication/pgdl-report
excerpt: 'We study generalization in deep learning by appealing to complexity measures originally developed in approximation and information theory.'
date: 2020-12-13
venue: 'PGDL Competition at NeurIPS 2020'
paperurl: 'https://arxiv.org/pdf/2012.06969'
citation: 'A Rajagopal, Vamshi C Madala, S Chandrasekaran, P Larson - arXiv preprint arXiv:2012.06969, 2020'
---
We study generalization in deep learning by appealing to complexity measures originally developed in approximation and information theory. While these concepts are challenged by the high-dimensional and data-defined nature of deep learning, we show that simple vector quantization approaches such as PCA, GMMs, and SVMs capture their spirit when applied layer-wise to deep extracted features giving rise to relatively inexpensive complexity measures that correlate well with generalization performance. We discuss our results in 2020 NeurIPS PGDL challenge.

[Download paper here](https://arxiv.org/pdf/2012.06969)

Recommended citation: 'A Rajagopal, Vamshi C Madala, S Chandrasekaran, P Larson - arXiv preprint arXiv:2012.06969, 2020'
